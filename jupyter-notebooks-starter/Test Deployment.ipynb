{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Load Data for Testing"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Test Deployment\n\nProvide the **Scoring URI** and **API Key** for the deployed webservice"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "web_service_url = 'http://40.121.22.12:80/api/v1/service/compliance-classifier-service/score' # provide the scoring URI\napi_key = '0eukNRewJss1wBU23ddSAnWGfXN7qk7M' # provide API key",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport numpy as np\nimport pandas as pd\n\ndata_url = ('https://davewdemoblobs.blob.core.windows.net/mlops/components.csv')\n\n# Load the car components labeled data\ncar_components_df = pd.read_csv(data_url)\ncomponents = car_components_df[\"text\"].tolist()\nlabels = car_components_df[\"label\"].tolist()\n\nmaxlen = 100                                               \nmax_words = 10000      \n\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(components)\nsequences = tokenizer.texts_to_sequences(components)\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\n\ndata = pad_sequences(sequences, maxlen=maxlen)\n\nlabels = np.asarray(labels)\n\nindices = np.arange(data.shape[0])                     \nnp.random.shuffle(indices)\ndata = data[indices]\nlabels = labels[indices]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Prepare Test Data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "test_size = 10\n\nx_test = data[0:test_size]\ny_test = labels[0:test_size]\n\nprint('Shape of test data tensor:', x_test.shape)\nprint('Shape of test label tensor:', y_test.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Make HTTP calls to test the deployed Webservice"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\nimport json\n\nheaders = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\nresponse = requests.post(web_service_url, json.dumps(x_test.tolist()), headers=headers)\nprint('Predictions')\nprint(response.text)\nprint('Labels')\nprint(y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}