{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Load Data for Testing"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport numpy as np\nimport pandas as pd\n\ndata_url = ('https://quickstartsws9073123377.blob.core.windows.net/'\n            'azureml-blobstore-0d1c4218-a5f9-418b-bf55-902b65277b85/'\n            'quickstarts/connected-car-data/connected-car_components.csv')\n\n# Load the car components labeled data\ncar_components_df = pd.read_csv(data_url)\ncomponents = car_components_df[\"text\"].tolist()\nlabels = car_components_df[\"label\"].tolist()\n\nmaxlen = 100                                               \nmax_words = 10000      \n\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(components)\nsequences = tokenizer.texts_to_sequences(components)\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\n\ndata = pad_sequences(sequences, maxlen=maxlen)\n\nlabels = np.asarray(labels)\n\nindices = np.arange(data.shape[0])                     \nnp.random.shuffle(indices)\ndata = data[indices]\nlabels = labels[indices]",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Found 65 unique tokens.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Prepare Test Data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "test_size = 10\n\nx_test = data[0:test_size]\ny_test = labels[0:test_size]\n\nprint('Shape of test data tensor:', x_test.shape)\nprint('Shape of test label tensor:', y_test.shape)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Shape of test data tensor: (10, 100)\nShape of test label tensor: (10,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Test Deployment\n\nProvide the **Scoring URI** and **API Key** for the deployed webservice"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "web_service_url = '' # provide the scoring URI\napi_key = '' # provide API key",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Make HTTP calls to test the deployed Webservice"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\nimport json\n\nheaders = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\nresponse = requests.post(web_service_url, json.dumps(x_test.tolist()), headers=headers)\nprint('Predictions')\nprint(response.text)\nprint('Labels')\nprint(y_test)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Predictions\n\"[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\"\nLabels\n[1 0 1 0 1 1 0 1 0 1]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}